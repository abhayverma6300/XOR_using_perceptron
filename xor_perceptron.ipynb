{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wicked-johnson",
   "metadata": {},
   "source": [
    "# XOR using Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fossil-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Input data\n",
    "X = np.array([[0, 0, 1], [1, 0, 1], [0, 1, 1], [1, 1, 1]])\n",
    "# Target output\n",
    "Y = np.array([[0], [0], [0], [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e2d35ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function (Sigmoid)\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of the Sigmoid function\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c57cc68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random number generator\n",
    "rand = np.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "directed-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network architecture\n",
    "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 3, 4, 1\n",
    "\n",
    "# Initialize random weights for hidden and output layers\n",
    "hidden_weights = rand.uniform(size=(inputLayerNeurons, hiddenLayerNeurons))\n",
    "output_weights = rand.uniform(size=(hiddenLayerNeurons, outputLayerNeurons))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee31735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation function\n",
    "def forward_propagation(X, W1, W2):\n",
    "    hidden_layer_activation = np.dot(X, W1)\n",
    "    hidden_layer_output = sigmoid(hidden_layer_activation)\n",
    "    output_layer_activation = np.dot(hidden_layer_output, W2)\n",
    "    predicted_output = sigmoid(output_layer_activation)\n",
    "    return hidden_layer_output, predicted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "generic-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward propagation function\n",
    "def backward_propagation(X, Y, hidden_layer_output, predicted_output, W1, W2, lr):\n",
    "    # Calculate errors and derivatives\n",
    "    error_output = Y - predicted_output\n",
    "    d_predicted_output = error_output * sigmoid_derivative(predicted_output)\n",
    "\n",
    "    error_hidden_layer = d_predicted_output.dot(W2.T)\n",
    "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "    # Update weights\n",
    "    W2 += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
    "    W1 += X.T.dot(d_hidden_layer) * lr\n",
    "\n",
    "    return W1, W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4913c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(X, Y, hidden_weights, output_weights, lr=0.1, num_epoch=10000):\n",
    "    for epoch in range(num_epoch):\n",
    "        hidden_layer_output, predicted_output = forward_propagation(X, hidden_weights, output_weights)\n",
    "        hidden_weights, output_weights = backward_propagation(X, Y, hidden_layer_output, predicted_output, hidden_weights, output_weights, lr)\n",
    "\n",
    "        # Print error every 1000 epochs\n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Epoch:\", epoch, \"Error:\", np.mean(np.abs(Y - predicted_output)))\n",
    "\n",
    "    return hidden_weights, output_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prescription-johnston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Error: 0.6250188975714221\n",
      "Epoch: 1000 Error: 0.2779902987269207\n",
      "Epoch: 2000 Error: 0.09698193523350866\n",
      "Epoch: 3000 Error: 0.05915599114803323\n",
      "Epoch: 4000 Error: 0.04440672096964522\n",
      "Epoch: 5000 Error: 0.03644578128363639\n",
      "Epoch: 6000 Error: 0.03138844103959276\n",
      "Epoch: 7000 Error: 0.02785114056547624\n",
      "Epoch: 8000 Error: 0.025215629390599792\n",
      "Epoch: 9000 Error: 0.023162555714271785\n"
     ]
    }
   ],
   "source": [
    "# Train the perceptron\n",
    "hidden_weights, output_weights = train(X, Y, hidden_weights, output_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "norwegian-prophet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output:\n",
      "[[0.00127999]\n",
      " [0.02484788]\n",
      " [0.0249315 ]\n",
      " [0.96502142]]\n"
     ]
    }
   ],
   "source": [
    "# Test the perceptron\n",
    "_, predicted_output = forward_propagation(X, hidden_weights, output_weights)\n",
    "print(\"Predicted Output:\")\n",
    "print(predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-presentation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
